########################################################################
环境：centos6.5，桥接

########################################################################
准备：
一、关selinux 和 iptables
[root@base ~]# vi /etc/selinux/config
[root@base ~]# chkconfig iptables off
二、安装jdk
配置环境变量：/etc/profile
JAVA_HOME=/usr/java/jdk1.6.0_45
JRE_HOME=$JAVA_HOME/jre
PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib
export JAVA_HOME JRE_HOME PATH CLASSPATH

.bash_logout 配置用户登录出去执行什么
.bash_profile 配置用户特殊的profile
.bashrc 配置bash专用的(bash是一种shell linux 可以有很多种shell 比如C shell 就是C语言风格的shell 如果用C shell 这个文件就没用了)
############################################################################
配置网络环境：/etc/sysconfig/network-scripts/ifcfg-eth0
#开机启动网卡
ONBOOT=yes



启动网络服务
service network restart
#如果不能成功启动则reboot后再尝试
使用ifconfig查看本机ip

修改主机名
[root@hadoop CentOS]# vi /etc/sysconfig/network
HOSTNAME=hadoop

修改完成后reboot生效

修改/etc/hosts
主机ip master
从机ip slave1
...

修改 /etc/security/limits.conf 最后加 配置最大线程和文件打开数
* - nproc 65535
* - nofile 65535

############################################################################
本地镜像安装openssh-client
在media下创建CentOS 文件夹
[root@hadoop media]# mkdir CentOS

挂载光盘至/media/CentOS目录下（这样可以不用修改yum相应配置文件）
 mount /dev/cdrom /media/CentOS/

查看配置文件
[root@hadoop CentOS]# more /etc/yum.repos.d/CentOS-Media.repo 
记录第12行：
如：#  yum --disablerepo=\* --enablerepo=c6-media [command]
使用上条命令安装openssh-client
[root@hadoop CentOS]# yum --disablerepo=\* --enablerepo=c6-media install openssh-clients -y


############################################################################
创建hadoop用户
useradd hadoop

设置密码
passwd hadoop

############################################################################
配置ssh无密码验证
确保创建了 hadoop 这个用户 执行以下命令
su - hadoop
mkdir ~/.ssh
cd ~/.ssh
ssh-keygen -t rsa -P ''

cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys

chmod 600 authorized_keys

root 用户编辑 /etc/ssh/sshd_config
vi /etc/ssh/sshd_config

去掉 26行 左右 以下配置的注释
HostKey /etc/ssh/ssh_host_rsa_key

去掉 47 48 49 行的注释 (对应下面这三行)


RSAAuthentication yes
PubkeyAuthentication yes
AuthorizedKeysFile      .ssh/authorized_keys

配置.ssh权限防止没权限读取ssh的秘钥
***一定要使用hadoop用户执行不能root代劳***


chown -R hadoop:hadoop /home/hadoop
chmod 700 /home/hadoop
chmod 700 /home/hadoop/.ssh
chmod 644 /home/hadoop/.ssh/authorized_keys
chmod 600 /home/hadoop/.ssh/id_rsa
############################################################################

hadoop 1.0.4 传到 虚拟机
放到 /home/hadoop 目录下
解压
tar -vxzf hadoop-1.0.4.tar.gz
修改解压后的目录名(mv 是移动文件 相当于改名)
mv hadoop-1.0.4 hadoop

mkdir ~/hadoop/data/
mkdir ~/hadoop/tmp/
chmod 755 ~/hadoop/data/
chmod 755 ~/hadoop/tmp/

配置hadoop用户目录下的 ~/.bash_profile
将以下内容编辑到文本末尾：
HADOOP_HOME=/home/hadoop/hadoop
PATH=$PATH:$HADOOP_HOME/bin
############################################################################
统一修改hadoop用户conf目录(~/hadoop/conf)下的各种配置文件

修改配置文件hadoop-env.sh
搜索到JAVA_HOME所在行，然后将默认的“#”去掉，也就是打开注释，然后如下配置：
export JAVA_HOME=/usr/java/jdk1.6.0_45

修改配置文件 core-site.xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!-- Put site-specific property overrides in this file. -->
<configuration>
 <property>
      <name>fs.default.name</name>
      <value>hdfs://master:9000</value>
 </property>
</configuration>

修改配置文件 hdfs-site.xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!-- Put site-specific property overrides in this file. -->
<configuration>
 <property>  
  <name>dfs.replication</name>
  <value>3</value>
 </property>            
 <property>  
   <name>dfs.name.dir</name>  
   <value>/home/hadoop/hadoop/namenode/</value>  
  </property> 
  <property>  
   <name>dfs.data.dir</name>  
   <value>/home/hadoop/hadoop/data/</value>  
  </property>               
  <property>  
    <name>hadoop.tmp.dir</name>  
    <value>/home/hadoop/hadoop/tmp/</value>  
  </property>
  <property>
   <name>dfs.permissions</name>
   <value>false</value>
  </property>
</configuration>

修改配置文件 mapred-site.xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!-- Put site-specific property overrides in this file. -->
<configuration>
 <property>  
   <name>mapred.job.tracker</name>  
   <value>master:9001</value>  
 </property>
 <property>  
   <name>mapred.tasktracker.map.tasks.maximum</name>  
   <value>2</value>  
 </property>                  
 <property>  
    <name>mapred.tasktracker.reduce.tasks.maximum</name>  
    <value>2</value>  
 </property>  
</configuration>

修改配置文件 masters
配置如下：
master

修改配置文件 slaves
配置如下：
slave1
slave2
slave3
############################################################################
复制虚拟机 并配置IP
vm_master 主机ip
vm_slave1 从机ip
...
############################################################################
hadoop namenode -format
启动hadoop：
start-all.sh
启动后使用jps命令查看：
NN上：
jps
namenode 1002
secondarynamenode 1011
jobtracker 1012
DN上：
jps
datanode 2
tasktracker 10
然后通过http://master:50070和http://master:50030查看监控界面。
